{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QLearning_Taxi.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGMsibk5gQe4SZgdtk7EPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CeHaga/qlearning-taxi/blob/main/QLearning_Taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FuOm5rli0JY"
      },
      "source": [
        "# Q-Learning Algorithm in OpenAi Gym\n",
        "This notebook implements q-learning algorithm for reinforcement learning in OpenAI Gym's Taxi environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxbbcON1i3Yk"
      },
      "source": [
        "## Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB8OZ-i_ioGv"
      },
      "source": [
        "import numpy as np\n",
        "import random # Exploration X Exploit\n",
        "from IPython.display import clear_output\n",
        "import gym # Environment\n",
        "from time import sleep"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc6A1_Yli5ai"
      },
      "source": [
        "The Taxi environment is a 5x5 grid where the player controls a taxi and must pickoff a passanger from one of the 4 corners and deliver it to the desired corner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIYrNaxJioqr",
        "outputId": "31a7d039-f2c5-4f32-fd75-1a711a8d2833"
      },
      "source": [
        "env = gym.make(\"Taxi-v3\").env\n",
        "env.render()\n",
        "\n",
        "print('There are {} states (5x5 grid * 5 passanger location * 4 destinations)'.format(env.observation_space.n))\n",
        "print('There are {} actions (4 directions + pickup + dropoff)'.format(env.action_space.n))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : :\u001b[43m \u001b[0m|\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "There are 500 states (5x5 grid * 5 passanger location * 4 destinations)\n",
            "There are 6 actions (4 directions + pickup + dropoff)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8lO0433jQ8H"
      },
      "source": [
        "## Variable Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUlpIXoWjXKR"
      },
      "source": [
        "*   Alpha: Learning Rate\n",
        "*   Gamma: Future Reward Importance\n",
        "*   Epsilon: Random Action Frequency\n",
        "*   Episode: Session from start to end\n",
        "\n",
        "The Q-Table maps a given state and action to the corresponding reward, initialize it with 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ika5eVdjS0R"
      },
      "source": [
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "nEpisodes = 10000\n",
        "ckpEpisode = 1000\n",
        "nCkp = int(nEpisodes/ckpEpisode)\n",
        "q = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "frames = [[] for _ in range(nCkp)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jlh58oGkU8s"
      },
      "source": [
        "## Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "504YDA_ZkYyk",
        "outputId": "6a19c504-e5ba-4031-971e-6da8c1464b62"
      },
      "source": [
        "for episode in range(nEpisodes):\n",
        "  state = env.reset() # Set environment to a initial state\n",
        "\n",
        "  reward = 0\n",
        "  terminated = False\n",
        "  action = 0\n",
        "\n",
        "  while not terminated:\n",
        "    if random.uniform(0,1) < epsilon: # If explore\n",
        "      action = env.action_space.sample() # Get a random action\n",
        "    else:\n",
        "      action = np.argmax(q[state]) # Get the best\n",
        "\n",
        "    nextState, reward, terminated, info = env.step(action) # Do the action\n",
        "\n",
        "    # Update Q based on formula\n",
        "    qValue = q[state, action]\n",
        "    maxValue = np.max(q[nextState])\n",
        "    qValue = (1 - alpha) * qValue + alpha * (reward + gamma * maxValue)\n",
        "    q[state, action] = qValue\n",
        "\n",
        "    state = nextState\n",
        "\n",
        "    # Save the env frame after ckpEpisode episodes\n",
        "    if((episode + 1) % ckpEpisode == 0):\n",
        "      epInd = int((episode+1)/ckpEpisode)-1\n",
        "      frames[epInd].append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward\n",
        "        }\n",
        "      )\n",
        "  \n",
        "  if((episode + 1) % ckpEpisode == 0):\n",
        "    clear_output(wait=True)\n",
        "    print(\"({}%) Episode {} of {}\".format(((episode+1)/nEpisodes)*100,episode+1,nEpisodes))\n",
        "\n",
        "print('='*30)\n",
        "print('\\tTraining Over!')\n",
        "print('='*30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100.0%) Episode 10000 of 10000\n",
            "==============================\n",
            "\tTraining Over!\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpDcvGbrbRsU",
        "outputId": "0db6ee22-9150-4c31-ac75-47a3e788ccc4"
      },
      "source": [
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(0.4)\n",
        "        \n",
        "print_frames(frames[9])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 25\n",
            "State: 410\n",
            "Action: 5\n",
            "Reward: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkpnKFseQL-X",
        "outputId": "b8baf41f-054a-45f1-9fab-65a0e2a1ef0a"
      },
      "source": [
        "totalEpochs = 0\n",
        "totalPenalties = 0\n",
        "totalTimeoffs = 0\n",
        "nEpisodes = 100\n",
        "\n",
        "# Repeat best action for nEpisodes to compare penalties\n",
        "for episode in range(nEpisodes):\n",
        "  state = env.reset()\n",
        "  \n",
        "  epochs = 0\n",
        "  penalties = 0\n",
        "  timeoffs = 0\n",
        "  reward = 0\n",
        "  terminated = False\n",
        "  limit = 500\n",
        "\n",
        "  while not terminated:\n",
        "    action = np.argmax(q[state])\n",
        "    state, reward, terminated, info = env.step(action)\n",
        "\n",
        "    if(reward == -10):\n",
        "      penalties += 1\n",
        "\n",
        "    epochs += 1\n",
        "    if(epochs == limit):\n",
        "      timeoffs += 1\n",
        "      break\n",
        "\n",
        "  totalPenalties += penalties\n",
        "  totalEpochs += epochs\n",
        "  totalTimeoffs += timeoffs\n",
        "\n",
        "print('*'*25)\n",
        "print(\"\\tResults\")\n",
        "print('*'*25)\n",
        "print(\"Epochs per episode: {}\".format(totalEpochs / nEpisodes))\n",
        "print(\"Penalties per episode: {}\".format(totalPenalties / nEpisodes))\n",
        "print(\"Timeoffs per episode: {}\".format(totalTimeoffs / nEpisodes))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\tResults\n",
            "*************************\n",
            "Epochs per episode: 13.09\n",
            "Penalties per episode: 0.0\n",
            "Timeoffs per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4QLi991i8Cd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Credits\n",
        "\n",
        "Made by Carlos Bravo\n",
        "\n",
        "GitHub: https://github.com/CeHaga\n",
        "\n",
        "Telegram: @CeHaga"
      ]
    }
  ]
}